# Phase 2 Implementation Plan: Voice & AI Intelligence

This document outlines the detailed steps for implementing Phase 2 of the AI Music Looper Agent.

**Update:** This plan has been revised to include significant UX improvements based on initial feedback. The core goals remain, but the user interaction model and underlying state management will be enhanced.

## 1. Core Objectives

-   **Voice Input:** ✅ Replace manual text/curl commands with real-time speech-to-text using `SFSpeechRecognizer`.
-   **Voice Output:** ✅ Enable the agent to provide spoken feedback using `AVSpeechSynthesizer`.
-   **Natural Language Understanding (NLU):** ✅ Upgrade the Python agent's router to understand a variety of commands.
-   **Stateful Track Manipulation:** ✅ Implement the ability to modify specific properties of individual tracks, starting with volume.
-   **UX Improvement - Record/Stop Toggle:** ✅ Implement a dedicated button for starting and stopping recording, separating this precise action from conversational commands.
-   **UX Improvement - Non-Destructive Muting:** ✅ Allow tracks to be muted (volume set to 0) without being removed from the session, so they can be unmuted later.

## 2. Implementation History & Architectural Fixes (✅ COMPLETE)

During the initial implementation, several key architectural improvements were made:

-   **Centralized Audio Engine:** Fixed a flaw where `SpeechManager` and `AudioManager` both tried to control the audio hardware. The `AudioManager` is now the single source of truth for all audio input and output.
-   **Audio Consumer Pattern:** Implemented a publisher/subscriber pattern within `AudioManager` so multiple components (e.g., the loop recorder and the speech recognizer) can consume the live audio stream simultaneously without conflict.
-   **Privacy Manifest:** Added the required `NSSpeechRecognitionUsageDescription` and `NSMicrophoneUsageDescription` keys to `Info.plist` to comply with macOS privacy standards.

## 3. Revised Implementation Steps

### Part 1: Python Backend - Agent Intelligence (✅ COMPLETE)

The Python backend was successfully upgraded from a simple keyword-based router to a stateful, agentic system capable of managing multiple tracks and properties.

### Part 2: Swift Frontend - Voice & Audio Control (✅ COMPLETE)

The native frontend was successfully updated to include:
- A `SpeechManager` for STT/TTS.
- An enhanced `AudioManager` with volume controls.
- An updated `AgentClient` for handling more complex JSON.
- A basic `ContentView` with a push-to-talk button.

---
## 4. NEW: UX Improvement Implementation Plan (✅ COMPLETE)

This section details the next steps to implement the improved user experience.

### **Part 4.1: Backend State & Logic (Python)** (✅ COMPLETE)

1.  **Enhance `Track` State:** ✅ Update the `Track` TypedDict in `python/main.py` to include a new field: `is_playing: bool`. This will track whether a loop is active or muted.
2.  **Update Router:** ✅ Expand the `router_node` to understand "mute" and "unmute" commands.
3.  **Create `TogglePlaybackNode`:** ✅ Add a new node to the graph that handles the logic for muting/unmuting. It will find the target track in the `AgentState`, flip its `is_playing` flag, and prepare a command for Swift (`{"action": "mute_track", ...}` or `{"action": "unmute_track", ...}`).

### **Part 4.2: Frontend Audio Control (Swift)** (✅ COMPLETE)

1.  **Refactor `AudioManager.swift`:**
    *   ✅ Ensure `AVAudioPlayerNode`s start playing immediately upon creation (at volume 0 if muted, or their set volume if unmuted) to maintain sync.
    *   ✅ Implement `muteTrack(trackID: String)` which will set the player's volume to `0.0`.
    *   ✅ Implement `unmuteTrack(trackID: String, volume: Float)` which will restore the player's volume to its state-managed level.

### **Part 4.3: Frontend UI (Swift)** (✅ COMPLETE)

1.  **Redesign `ContentView.swift`:**
    *   ✅ Replace the single push-to-talk button with two distinct controls:
        *   **Record/Stop Toggle Button:** A stateful button that sends a "record" or "stop" command on first/second tap.
        *   **Push-to-Talk Button:** A separate button for all conversational commands (e.g., "mute the last loop").
2.  **Refine Agent Router Logic:**
    *   ✅ **Update `python/main.py`** to use exact matching for "record" and "stop" commands. This prevents spoken commands (e.g., "please record this") from accidentally triggering the recording functions, reserving that control exclusively for the UI button.

## 5. Testing & Verification for UX Improvements

1.  **Click "Record".** Expected: Recording starts. The button changes to "Stop".
2.  **Click "Stop".** Expected: Recording stops, a new loop is created and starts playing. The button reverts to "Record".
3.  **Speak "mute the last track".** Expected: The most recently created loop becomes silent. The agent's state for that track should show `is_playing: false`.
4.  **Speak "unmute the last track".** Expected: The track's audio is audible again at its previous volume. The agent's state should show `is_playing: true`. 
5.  **Speak "quieter".** Expected: The track's audio is quieter than it's previous volume.